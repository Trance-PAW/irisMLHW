{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto de Clasificación de Iris\n",
    "\n",
    "Este proyecto implementa un pipeline de aprendizaje automático utilizando el dataset Iris, que incluye clasificación con Regresión Logística. También se explora la optimización de hiperparámetros mediante GridSearchCV y se ofrecen métricas detalladas para evaluar el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset de Iris\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. División de Datos en Entrenamiento y Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Mostrar las dimensiones de los datos\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación del Pipeline de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear el pipeline con escalado y clasificación\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predecir sobre los datos de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Imprimir un informe de clasificación detallado\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimización de Hiperparámetros con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el grid de hiperparámetros\n",
    "param_grid = {\n",
    "    'logreg__C': [0.1, 1, 10, 100],\n",
    "    'logreg__solver': ['liblinear', 'lbfgs'],\n",
    "    'logreg__max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Crear el GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros encontrados\n",
    "print(f\"Mejores parámetros encontrados: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardar el Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(grid_search.best_estimator_, 'iris_pipeline_model.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cargar el Modelo y Usarlo para Predicciones Futuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo guardado\n",
    "loaded_model = joblib.load('iris_pipeline_model.sav')\n",
    "\n",
    "# Realizar una predicción con nuevos datos (ejemplo)\n",
    "nuevos_datos = [[5.1, 3.5, 1.4, 0.2]]  # Características de una nueva flor\n",
    "prediccion = loaded_model.predict(nuevos_datos)\n",
    "print(f\"Clase predicha: {iris.target_names[prediccion[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licencia\n",
    "Este proyecto está licenciado bajo la Licencia MIT."
   ]
  }
 ],
 "metadata
